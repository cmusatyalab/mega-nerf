{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "from pathlib import Path\n",
    "import argparse\n",
    "import numpy as np\n",
    "import torch\n",
    "import glob\n",
    "import PIL.Image as pil\n",
    "import cv2\n",
    "from  matplotlib import pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torchvision import transforms\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "\n",
    "import transformations\n",
    "basepath = \"/home/wuzr/dir/time_func/NewYork_hard\"\n",
    "# mega_path = \"Datasets/high-simple\"\n",
    "mega_path = \"./datasets/hardnew\"\n",
    "K = np.array([[480,0.000000, 480 ,0.000000],\n",
    "[0.000000 ,480 ,240 ,0.000000],\n",
    "[0.000000 ,0.000000 ,1.000000 ,0.000000],\n",
    "[0.000000 ,0.000000 ,0.000000 ,1.000000]])\n",
    "K_inv = np.linalg.inv(K)\n",
    "if not os.path.exists(mega_path):\n",
    "    os.makedirs(mega_path)\n",
    "distortion = np.array([0,0,0,0])\n",
    "pose_scale_factor = 1 #根据下面自动来，把位姿放缩为[-1,1]\n",
    "num_val = 10\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "84 84\n"
     ]
    }
   ],
   "source": [
    "depth_names = [x for x in Path(basepath+\"/depth_aligned\").iterdir() if x.suffix == '.pfm']\n",
    "rgb_names = [x for x in Path(basepath+\"/rgb\").iterdir() if x.suffix == '.jpg']\n",
    "rgb_names = sorted(rgb_names, key= lambda x:x.stem)\n",
    "depth_names = sorted(depth_names, key= lambda x:x.stem)\n",
    "print(len(rgb_names), len(depth_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = np.zeros(len(rgb_names))\n",
    "for i,n in enumerate(depth_names):\n",
    "    for i2, n2 in enumerate(rgb_names):\n",
    "        if n2.stem == n.stem:\n",
    "            mask[i2] = 1\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "if mask.sum() == len(depth_names):\n",
    "    rgb_names_new = np.array(rgb_names)[np.arange(len(rgb_names))[mask.astype(np.bool_)]]\n",
    "origin_sample = np.arange(len(rgb_names))\n",
    "depth_names_down = np.array(depth_names)[origin_sample]\n",
    "rgb_names_new_down = np.array(rgb_names_new)[origin_sample]\n",
    "# poses_down = np.loadtxt(basepath+\"/hard.txt\").reshape(-1,4,4)[origin_sample]\n",
    "\n",
    "poses_down = np.zeros((len(rgb_names_new_down), 4, 4))\n",
    "for i, rgb_name in enumerate(rgb_names_new_down):\n",
    "    pose_filename = rgb_name.parent/ f'{rgb_name.stem}.txt'\n",
    "    pose = np.loadtxt(pose_filename).reshape(4, 4)\n",
    "    poses_down[i] = pose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "depths = depth_names_down\n",
    "images = rgb_names_new_down"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_pfm(data, fpath, scale=1, file_identifier=b'Pf', dtype=\"float32\"):\n",
    "    # PFM format definition: http://netpbm.sourceforge.net/doc/pfm.html\n",
    "\n",
    "    data = np.flipud(data)\n",
    "    height, width = np.shape(data)[:2]\n",
    "    values = np.ndarray.flatten(np.asarray(data, dtype=dtype))\n",
    "    endianess = data.dtype.byteorder\n",
    "    # print(endianess)\n",
    "\n",
    "    if endianess == '<' or (endianess == '=' and sys.byteorder == 'little'):\n",
    "        scale *= -1\n",
    "    with open(fpath, 'wb') as file:\n",
    "        file.write((file_identifier))\n",
    "        file.write(('\\n%d %d\\n' % (width, height)).encode())\n",
    "        file.write(('%d\\n' % scale).encode())\n",
    "\n",
    "        file.write(values)\n",
    "        \n",
    "\n",
    "        \n",
    "def read_pfm(fpath, expected_identifier=\"Pf\"):\n",
    "    # PFM format definition: http://netpbm.sourceforge.net/doc/pfm.html\n",
    "    \n",
    "    def _get_next_line(f):\n",
    "        next_line = f.readline().decode('utf-8').rstrip()\n",
    "        # ignore comments\n",
    "        while next_line.startswith('#'):\n",
    "            next_line = f.readline().rstrip()\n",
    "        return next_line\n",
    "    \n",
    "    with open(fpath, 'rb') as f:\n",
    "        #  header\n",
    "        identifier = _get_next_line(f)\n",
    "        if identifier != expected_identifier:\n",
    "            raise Exception('Unknown identifier. Expected: \"%s\", got: \"%s\".' % (expected_identifier, identifier))\n",
    "\n",
    "        try:\n",
    "            line_dimensions = _get_next_line(f)\n",
    "            dimensions = line_dimensions.split(' ')\n",
    "            width = int(dimensions[0].strip())\n",
    "            height = int(dimensions[1].strip())\n",
    "        except:\n",
    "            raise Exception('Could not parse dimensions: \"%s\". '\n",
    "                            'Expected \"width height\", e.g. \"512 512\".' % line_dimensions)\n",
    "\n",
    "        try:\n",
    "            line_scale = _get_next_line(f)\n",
    "            scale = float(line_scale)\n",
    "            assert scale != 0\n",
    "            if scale < 0:\n",
    "                endianness = \"<\"\n",
    "            else:\n",
    "                endianness = \">\"\n",
    "        except:\n",
    "            raise Exception('Could not parse max value / endianess information: \"%s\". '\n",
    "                            'Should be a non-zero number.' % line_scale)\n",
    "\n",
    "        try:\n",
    "            data = np.fromfile(f, \"%sf\" % endianness)\n",
    "            data = np.reshape(data, (height, width))\n",
    "            data = np.flipud(data)\n",
    "            with np.errstate(invalid=\"ignore\"):\n",
    "                data *= abs(scale)\n",
    "        except:\n",
    "            raise Exception('Invalid binary values. Could not create %dx%d array from input.' % (height, width))\n",
    "\n",
    "        return data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "poses = []\n",
    "inv_pose = None#应该禁用（逆乘第一个位姿）这个不然全局变成了第一个的局部 这里修改只做平移\n",
    "c2b = np.array([[0,0,1,0],[1,0,0,0],[0,1,0,0],[0,0,0,1]])\n",
    "for b2w in poses_down:\n",
    "    c2w = b2w @ transformations.euler_matrix(0,-1.39626,0) @ c2b  \n",
    "    # c2w = b2w  @ transformations.euler_matrix(0,-np.pi/2,0) @ c2b  \n",
    "    if inv_pose is None:\n",
    "        inv_pose = np.eye(4)\n",
    "        inv_pose[:3,3] = -c2w[:3,3]\n",
    "        c2w = inv_pose @ c2w\n",
    "        c2w_RDF = np.linalg.inv(c2b) @ c2w\n",
    "    else:\n",
    "        c2w = inv_pose @ c2w #相当于位值为相对第一帧\n",
    "        c2w_RDF = np.linalg.inv(c2b) @ c2w\n",
    "    # c2w = torch.from_numpy(c2w).float()\n",
    "    # poses += [c2w]\n",
    "    c2w_RDF = torch.from_numpy(c2w_RDF).float()\n",
    "    poses += [c2w_RDF]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.return_types.min(\n",
      "values=tensor([-61.1852,  -0.2647,   0.0000]),\n",
      "indices=tensor([63, 37,  0])) torch.return_types.max(\n",
      "values=tensor([5.0655e+01, 1.2669e-01, 1.9450e+02]),\n",
      "indices=tensor([24, 76, 37]))\n"
     ]
    }
   ],
   "source": [
    "print(torch.stack(poses)[:,:3,3].min(axis=0),torch.stack(poses)[:,:3,3].max(axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  1.8,   0. , 180. ])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.linalg.inv(c2b)[:3,:3] @ np.array([180,1.8,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3, 1, 2])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c2b[:3,:3] @ np.array([1,2,3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2., 3., 1.])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.linalg.inv(c2b)[:3,:3] @ np.array([1,2,3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-2.,  1.,  3.])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transformations.euler_matrix(0,-np.pi/2,0)[:3,:3] @ c2b[:3,:3] @ np.array([1,2,3]) # 因为这个rpy角是相对b的"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "84 images\n"
     ]
    }
   ],
   "source": [
    "RDF_TO_DRB = torch.FloatTensor([[0, 1, 0],\n",
    "                                [1, 0, 0],\n",
    "                                [0, 0, -1]])#右下前变为下右后（相机坐标一般都是右下前）\n",
    "mega_poses = []\n",
    "for c2w in poses:\n",
    "    c2w = torch.hstack((\n",
    "    RDF_TO_DRB @ c2w[:3, :3] @ torch.inverse(RDF_TO_DRB),\n",
    "    RDF_TO_DRB @ c2w[:3, 3:]))\n",
    "    mega_poses.append(c2w)\n",
    "positions = torch.cat([c2w[:3, 3].unsqueeze(0) for c2w in mega_poses])\n",
    "print('{} images'.format(positions.shape[0]))\n",
    "max_values = positions.max(0)[0]\n",
    "min_values = positions.min(0)[0]\n",
    "origin = ((max_values + min_values) * 0.5)\n",
    "dist = (positions - origin).norm(dim=-1)\n",
    "diagonal = dist.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([  0.3914, 111.8402, 194.5003])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_values - min_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0.1267, 50.6550,  0.0000])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([  -0.2647,  -61.1852, -194.5003])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "min_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-6.8993e-02, -5.2651e+00, -9.7250e+01])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "origin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([6.8993e-02, 5.2651e+00, 9.7250e+01])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(torch.eye(4)[:3, 3] - origin) / pose_scale_factor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "pose_scale_factor = torch.abs(positions).max() + 1 #除法，放缩几倍\n",
    "pose_scale_factor = 200 #先写死"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(194.5003)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.abs(positions).max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(os.path.join(mega_path,\"train/metadata\")): os.makedirs(os.path.join(mega_path,\"train/metadata\"))\n",
    "if not os.path.exists(os.path.join(mega_path,\"val/metadata\")): os.makedirs(os.path.join(mega_path,\"val/metadata\"))\n",
    "if not os.path.exists(os.path.join(mega_path,\"train/rgbs\")): os.makedirs(os.path.join(mega_path,\"train/rgbs\"))\n",
    "if not os.path.exists(os.path.join(mega_path,\"val/rgbs\")): os.makedirs(os.path.join(mega_path,\"val/rgbs\"))\n",
    "if not os.path.exists(os.path.join(mega_path,\"train/depth\")): os.makedirs(os.path.join(mega_path,\"train/depth\"))\n",
    "if not os.path.exists(os.path.join(mega_path,\"val/depth\")): os.makedirs(os.path.join(mega_path,\"val/depth\"))\n",
    "if not os.path.exists(os.path.join(mega_path,\"train/depthvis\")): os.makedirs(os.path.join(mega_path,\"train/depthvis\"))\n",
    "if not os.path.exists(os.path.join(mega_path,\"val/depthvis\")): os.makedirs(os.path.join(mega_path,\"val/depthvis\"))\n",
    "\n",
    "coordinates = {\n",
    "    'origin_drb': origin,\n",
    "    'pose_scale_factor': pose_scale_factor\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 84/84 [00:02<00:00, 36.19it/s]\n"
     ]
    }
   ],
   "source": [
    "with open(os.path.join(mega_path,'mappings.txt'),mode='w') as f:\n",
    "    for idx, _ in enumerate(tqdm(images)):\n",
    "        if idx % int(positions.shape[0] / num_val) == 0:\n",
    "            split_dir = os.path.join(mega_path,\"val\")\n",
    "        else:\n",
    "            split_dir = os.path.join(mega_path,\"train\")\n",
    "        color = cv2.imread(str(images[idx]),-1)\n",
    "        cv2.imwrite(os.path.join(split_dir,'rgbs','{0:06d}.jpg'.format(idx)),color)\n",
    "        depth = read_pfm(str(depths[idx]))\n",
    "        # depth = np.flip(depth,axis=0)\n",
    "        write_pfm(depth,os.path.join(split_dir,'depth','{0:06d}.pfm'.format(idx)))\n",
    "        depthvis = pil.fromarray(depth).convert('RGB')\n",
    "        depthvis.save(os.path.join(split_dir,'depthvis','{0:06d}.jpg'.format(idx)))\n",
    "        \n",
    "\n",
    "        camera_in_drb = mega_poses[idx].clone()#这个操作会改变原来的\n",
    "        camera_in_drb[:, 3] = (camera_in_drb[:, 3] - origin) / pose_scale_factor\n",
    "\n",
    "        assert np.logical_and(camera_in_drb >= -1, camera_in_drb <= 1).all()\n",
    "        \n",
    "\n",
    "        metadata_name = '{0:06d}.pt'.format(idx)\n",
    "        torch.save({\n",
    "            'H': color.shape[0],\n",
    "            'W': color.shape[1],\n",
    "            'c2w': torch.cat(\n",
    "                [camera_in_drb[:, 1:2], -camera_in_drb[:, :1], camera_in_drb[:, 2:4]],\n",
    "                -1),#变为右上后，又和nice-slam（nerf-pytorch保持一致了），局部为右上后，全局为下右后（不懂为啥要搞这么复杂）\n",
    "            'intrinsics': torch.FloatTensor(\n",
    "                [K[0][0], K[1][1], K[0][2], K[1][2]]),\n",
    "            'distortion': torch.FloatTensor(distortion),\n",
    "            'timestamp': torch.tensor(float(images[idx].stem),dtype=torch.float64)\n",
    "        }, os.path.join(split_dir,'metadata',metadata_name))\n",
    "        f.write('{},{}\\n'.format('{0:06d}.jpg'.format(idx), metadata_name))\n",
    "\n",
    "torch.save(coordinates, os.path.join(mega_path,'coordinates.pt'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  5.91883707 -61.18521118 -80.81902313] [200.41912842  50.65497589 -80.42766571]\n"
     ]
    }
   ],
   "source": [
    "print(poses_down[:,:3,3].min(axis=0),poses_down[:,:3,3].max(axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.return_types.min(\n",
      "values=tensor([-61.1852,  -0.2647,   0.0000]),\n",
      "indices=tensor([63, 37,  0])) torch.return_types.max(\n",
      "values=tensor([5.0655e+01, 1.2669e-01, 1.9450e+02]),\n",
      "indices=tensor([24, 76, 37]))\n"
     ]
    }
   ],
   "source": [
    "print(torch.stack(poses)[:,:3,3].min(axis=0),torch.stack(poses)[:,:3,3].max(axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.return_types.min(\n",
      "values=tensor([  -0.2647,  -61.1852, -194.5003]),\n",
      "indices=tensor([37, 63, 37])) torch.return_types.max(\n",
      "values=tensor([ 0.1267, 50.6550,  0.0000]),\n",
      "indices=tensor([76, 24,  0]))\n"
     ]
    }
   ],
   "source": [
    "print(torch.stack(mega_poses)[:,:3,3].min(axis=0),torch.stack(mega_poses)[:,:3,3].max(axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.return_types.min(\n",
      "values=tensor([-0.0010, -0.2796, -0.4863]),\n",
      "indices=tensor([37, 63, 37])) torch.return_types.max(\n",
      "values=tensor([0.0010, 0.2796, 0.4863]),\n",
      "indices=tensor([76, 24,  0]))\n"
     ]
    }
   ],
   "source": [
    "a = []\n",
    "for c2w in mega_poses:\n",
    "    camera_in_drb = c2w.clone()#这个操作会改变原来的\n",
    "    camera_in_drb[:, 3] = (camera_in_drb[:, 3] - origin) / pose_scale_factor\n",
    "    a.append(torch.cat([camera_in_drb[:, 1:2], -camera_in_drb[:, :1], camera_in_drb[:, 2:4]],-1))\n",
    "print(torch.stack(a)[:,:3,3].min(axis=0),torch.stack(a)[:,:3,3].max(axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-6.8993e-02, -5.2651e+00, -9.7250e+01])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "origin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 ('mega-nerf')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "vscode": {
   "interpreter": {
    "hash": "55cb96f0c631e8b66045e0f487dcdc3e9529b9e05c3ed831e99813860793c1e0"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
